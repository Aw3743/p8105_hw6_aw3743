---
title: "P8105 Homework 6"
author: "Aisha Waggeh"
date: "`r Sys.Date()`"
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6,
  fig.path = "figs/",
  dev = "png"
)

library(tidyverse)
library(broom)
library(modelr)
library(p8105.datasets)


```

# Problem 1
```{r}
# Load and clean homicide data from GitHub
homicide_df <- read_csv(
  "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
) 
glimpse(homicide_df)

 homicide_df <- homicide_df %>%
  mutate(
    city_state = paste(city, state, sep = ", "),
    resolved = as.numeric(disposition == "Closed by arrest")
  ) %>%
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White"),
    victim_sex = fct_relevel(victim_sex, "Female")
  )

# Check structure of data
homicide_df |> 
  summarise(across(everything(), ~sum(is.na(.))))

# Check for missing data
homicide_df |> 
  filter(is.na(victim_age)) |> 
  count(city_state) |> 
  arrange(desc(n))

# Handling missing values
homicide_df = homicide_df |> 
  drop_na(victim_age) 

# Verify clean data
homicide_df |> 
  summarise(n = n(), missing_age = sum(is.na(victim_age)))

```


```{r}
# Baltimore analysis first
baltimore_df = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model
fit_logistic = 
  baltimore_df |> 
  glm(resolved ~ victim_age + victim_sex + victim_race, 
      data = _, 
      family = binomial())

# Results 
baltimore_results = 
  fit_logistic |> 
  broom::tidy() |> 
  mutate(OR = exp(estimate)) |> 
  filter(term == "victim_sexMale") |> 
  select(term, OR, p.value)

# Add confidence intervals 
baltimore_results_ci = 
  fit_logistic |> 
  broom::tidy(conf.int = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(conf.low),
    OR_CI_upper = exp(conf.high)
  ) |> 
  select(term, OR, OR_CI_lower, OR_CI_upper, p.value)

baltimore_results_ci

```

```{r}
# Function to fit model for each city
fit_city_model = function(df) {
  fit = glm(resolved ~ victim_age + victim_sex + victim_race, 
            data = df, 
            family = binomial())
  
  broom::tidy(fit, conf.int = TRUE) %>%
    filter(term == "victim_sexMale") %>%
    mutate(
      OR = exp(estimate),
      CI_lower = exp(conf.low),
      CI_upper = exp(conf.high)
    ) %>%
    select(OR, CI_lower, CI_upper)
}

# Apply to all cities
city_results = 
  homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
    model_results = map(data, fit_city_model)
  ) %>%
  select(-data) %>%
  unnest(model_results) %>%
  arrange(OR)

city_results

```

```{r}
# Create plot
city_plot = city_results %>%
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) %>%
  ggplot(aes(x = city_state, y = OR, ymin = CI_lower, ymax = CI_upper)) +
  geom_point() +
  geom_errorbar(width = 0.2) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratios for Homicide Resolution",
    subtitle = "Male vs Female Victims (95% Confidence Intervals)",
    x = "City",
    y = "Odds Ratio"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 8),
    plot.title = element_text(face = "bold")
  )

city_plot

```

**Interpretation of plot**

The plot shows the adjusted odds ratios (ORs) for homicide resolution comparing male to female victims
across cities. An OR below 1 indicates that male victims are less likely to have their cases resolved
compared to female victims. Cities like New York, NY and Baton Rouge, LA have the lowest ORs, 
suggesting greater disparity, while cities with ORs closer to 1 indicate more equal resolution rates.

# Problem 2

```{r}
# Load weather data
data("weather_df")

# Clean data
weather_clean = weather_df %>%
  select(tmax, tmin, prcp) %>%
  drop_na()

# Function for bootstrap statistics
bootstrap_stats = function(df) {
  boot_sample = sample_frac(df, replace = TRUE)
  
  fit = lm(tmax ~ tmin + prcp, data = boot_sample)
  
  # Extract r-squared
  r2 = broom::glance(fit)$r.squared
  
  # Extract betas and compute product
  betas = broom::tidy(fit) %>%
    filter(term %in% c("tmin", "prcp")) %>%
    pull(estimate)
  
  beta_product = if(length(betas) == 2) prod(betas) else NA
  
  tibble(r_squared = r2, beta_product = beta_product)
}

# Run bootstrap
set.seed(123)
n_boot = 5000

bootstrap_results = 
  tibble(boot_id = 1:n_boot) %>%
  mutate(
    stats = map(boot_id, ~bootstrap_stats(weather_clean))
  ) %>%
  unnest(stats)

# Calculate confidence intervals
ci_r2 = bootstrap_results %>%
  summarise(
    lower = quantile(r_squared, 0.025, na.rm = TRUE),
    upper = quantile(r_squared, 0.975, na.rm = TRUE)
  )

ci_beta = bootstrap_results %>%
  summarise(
    lower = quantile(beta_product, 0.025, na.rm = TRUE),
    upper = quantile(beta_product, 0.975, na.rm = TRUE)
  )

# Display CIs
ci_r2
ci_beta

```



```{r}

# Plot distributions
plot_r2 = bootstrap_results %>%
  ggplot(aes(x = r_squared)) +
  geom_histogram(bins = 50, fill = "lightblue", alpha = 0.7) +
  geom_vline(xintercept = ci_r2$lower, linetype = "dashed", color = "red") +
  geom_vline(xintercept = ci_r2$upper, linetype = "dashed", color = "red") +
  labs(
    title = "Bootstrap Distribution of R-squared",
    x = "R-squared",
    y = "Frequency"
  ) +
  theme_minimal()

plot_beta = bootstrap_results %>%
  ggplot(aes(x = beta_product)) +
  geom_histogram(bins = 50, fill = "lightgreen", alpha = 0.7) +
  geom_vline(xintercept = ci_beta$lower, linetype = "dashed", color = "red") +
  geom_vline(xintercept = ci_beta$upper, linetype = "dashed", color = "red") +
  labs(
    title = "Bootstrap Distribution of β1 × β2",
    x = "β1 × β2",
    y = "Frequency"
  ) +
  theme_minimal()

plot_r2
plot_beta
```

**Interpretation of bootstrap distributions:**

The bootstrap distributions show the variability in R-squared and the product of coefficients (β1 × β2)
across 5000 resamples. For R-squared, most resamples fall between 0.934 and 0.947, indicating high model fit.
For β1 × β2, the distribution is narrowly negative (-0.0082 to -0.0037), suggesting a small negative interaction effect between tmin and prcp on tmax in the model.

# Problem 3

```{r}

# 1. Load and clean data
birthweight_data <- read_csv("data/birthweight.csv")

# Check structure and summary
glimpse(birthweight_data)
summary(birthweight_data)

# Check for missing values
sum(is.na(birthweight_data))

# Convert categorical variables to factors
birthweight_data <- birthweight_data %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace)
  )

# 2. Build your model
# Based on domain knowledge and literature, I'll build a model with key predictors
# known to affect birth weight

model_fit <- lm(bwt ~ blength + gaweeks + delwt + smoken + mrace + fincome, 
                data = birthweight_data)

# Model summary
summary(model_fit)

# Check model diagnostics
model_fit %>%
  augment() %>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals")

# QQ plot for normality
model_fit %>%
  augment() %>%
  ggplot(aes(sample = .std.resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Normal Q-Q Plot")

# 3. Compare with two other models
# Model 1: Length at birth and gestational age (from problem 1)
model1 <- lm(bwt ~ blength + gaweeks, data = birthweight_data)

# Model 2: Head circumference, length, sex, and all interactions (from problem 2)
model2 <- lm(bwt ~ bhead + blength + babysex + 
               bhead*blength + bhead*babysex + blength*babysex + 
               bhead*blength*babysex, 
             data = birthweight_data)

# 4. Cross-validation to compare models
set.seed(123)  # For reproducibility

cv_df <- crossv_mc(birthweight_data, 100) %>%
  mutate(
    # Your model
    train_model = map(train, ~lm(bwt ~ blength + gaweeks + delwt + smoken + mrace + fincome, data = .)),
    
    # Model 1
    train_model1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
    
    # Model 2
    train_model2 = map(train, ~lm(bwt ~ bhead + blength + babysex + 
                                    bhead*blength + bhead*babysex + blength*babysex + 
                                    bhead*blength*babysex, data = .)),
    
    # Calculate RMSE for each model
    rmse_model = map2_dbl(train_model, test, ~rmse(model = .x, data = .y)),
    rmse_model1 = map2_dbl(train_model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(train_model2, test, ~rmse(model = .x, data = .y))
  )

# Compare RMSE distribution
cv_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>%
  mutate(model = fct_recode(model,
                            "My Model" = "model",
                            "Length + Gestation" = "model1",
                            "Head Circ + Length + Sex + Interactions" = "model2")) %>%
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin() +
  labs(title = "Model Comparison using Cross-Validated RMSE",
       x = "Model",
       y = "Root Mean Square Error (RMSE)") +
  theme_minimal() +
  theme(legend.position = "none")

# 5. Plot of model residuals vs fitted values for your model
birthweight_data %>%
  add_residuals(model_fit) %>%
  add_predictions(model_fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs Fitted Values (My Model)",
       x = "Fitted Values",
       y = "Residuals") +
  theme_minimal()


# cross-validation plot for futher justification:
cv_summary <- cv_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(everything(), names_to = "model", values_to = "rmse") %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse = sd(rmse),
    ci_lower = quantile(rmse, 0.025),
    ci_upper = quantile(rmse, 0.975)
  )

cv_summary

```

**Justification for model choice:**

My model (blength + gaweeks + delwt + smoken + mrace + fincome) achieves a cross-validated RMSE of 314.5 (95% CI: 299-341), representing a meaningful 16.2-point improvement over the simple length+gestation model (RMSE = 330.7, 95% CI: 312-363). This 4.9% reduction in prediction error demonstrates that including maternal factors—delivery weight, smoking status, race, and family income—adds substantial predictive value beyond basic biometric measures alone.

While the complex interaction model with head circumference, length, sex, and all three-way interactions achieves the lowest RMSE at 288.4 (95% CI: 273-306), my model offers important practical advantages:

1. **Clinical interpretability**: Each predictor in my model has a clear, evidence-based relationship with birthweight documented in the epidemiological literature. In contrast, the three-way interaction in Model 2, while statistically significant, is challenging to explain in clinical or public health terms and may represent overfitting to noise in the data.

2. **Actionable insights**: The factors in my model, particularly smoking cessation (smoken), maternal nutrition (proxied by delwt), and socioeconomic status (fincome) are potentially modifiable through interventions. This makes the model directly applicable for developing targeted clinical counseling or public health strategies.

3. **Optimal complexity**: My model uses 6 main effects (plus factor levels for mrace), compared to Model 2's 15 parameters including complex interactions. The narrower confidence interval for Model 2's RMSE (8.2 vs 11.3-12.6 for the other models) suggests it may be more sensitive to specific data patterns, potentially reducing generalizability.

4. **Performance tradeoff analysis**: The performance hierarchy shows my model captures approximately 84% of the predictive improvement from Model 1 to Model 2 [(330.7-314.5)/(330.7-288.4) = 0.84] while using only 53% as many parameters as Model 2 (8 vs 15). This represents an excellent efficiency gain in terms of predictive power per parameter.

For applications where understanding the mechanistic drivers of birthweight is as important as prediction accuracy such as clinical risk assessment, public health program design, or etiological research, my model represents an optimal choice. It balances biological plausibility, clinical interpretability, and robust predictive performance while avoiding the potential overfitting risks of highly complex interaction models.
